---
---
@inproceedings{vashishtha-etal-2024-famus,
  title     = {{FAM}u{S}: Frames Across Multiple Sources},
  abbr      = {NAACL-long},
  author    = {Vashishtha, Siddharth  and
               Martin, Alexander  and
               Gantt, William  and
               Van Durme, Benjamin  and
               White, Aaron},
  editor    = {Duh, Kevin  and
               Gomez, Helena  and
               Bethard, Steven},
  booktitle = {Proceedings of the 2024 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies (Volume 1: Long Papers)},
  month     = jun,
  year      = {2024},
  address   = {Mexico City, Mexico},
  publisher = {Association for Computational Linguistics},
  url       = {https://aclanthology.org/2024.naacl-long.457},
  pages     = {8250--8273},
  website   = {https://github.com/FACTSlab/FAMuS},
  selected  = {true},
  pdf       = {https://aclanthology.org/2024.naacl-long.457/}
  abstract  = {Understanding event descriptions is a central aspect of language processing, but current approaches focus overwhelmingly on single sentences or documents. Aggregating information about an event across documents can offer a much richer understanding. To this end, we present FAMuS, a new corpus of Wikipedia passages that report on some event, paired with underlying, genre-diverse (non-Wikipedia) source articles for the same event. Events and (cross-sentence) arguments in both report and source are annotated against FrameNet, providing broad coverage of different event types. We present results on two key event understanding tasks enabled by FAMuS: source validation{---}determining whether a document is a valid source for a target report event{---}and cross-document argument extraction{---}full-document argument extraction for a target event from both its report and the correct source article.}
}

@inproceedings{goel-etal-2023-presto,
    title = "{PRESTO}: A Multilingual Dataset for Parsing Realistic Task-Oriented Dialogs",
    abbr      = {EMNLP-long},
    author = "Goel, Rahul  and
      Ammar, Waleed  and
      Gupta, Aditya  and
      Vashishtha, Siddharth  and
      Sano, Motoki  and
      Surani, Faiz  and
      Chang, Max  and
      Choe, HyunJeong  and
      Greene, David  and
      He, Chuan  and
      Nitisaroj, Rattima  and
      Trukhina, Anna  and
      Paul, Shachi  and
      Shah, Pararth  and
      Shah, Rushin  and
      Yu, Zhou",
    editor = "Bouamor, Houda  and
      Pino, Juan  and
      Bali, Kalika",
    booktitle = "Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing",
    month = dec,
    year = "2023",
    address = "Singapore",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2023.emnlp-main.667",
    doi = "10.18653/v1/2023.emnlp-main.667",
    pages = "10820--10833",
    selected  = {true},
    pdf       = {https://aclanthology.org/2023.emnlp-main.667},
    website   = {https://github.com/google-research-datasets/presto},
    abstract = "Research interest in task-oriented dialogs has increased as systems such as Google Assistant, Alexa and Siri have become ubiquitous in everyday life. However, the impact of academic research in this area has been limited by the lack of datasets that realistically capture the wide array of user pain points. To enable research on some of the more challenging aspects of parsing realistic conversations, we introduce PRESTO, a public dataset of over 550K contextual multilingual conversations between humans and virtual assistants. PRESTO contains a diverse array of challenges that occur in real-world NLU tasks such as disfluencies, code-switching, and revisions. It is the only large scale human generated conversational parsing dataset that provides structured context such as a user{'}s contacts and lists for each example. Our mT5 model based baselines demonstrate that the conversational phenomenon present in PRESTO are challenging to model, which is further pronounced in a low-resource setup.",
}


@inproceedings{gantt-etal-2023-event,
  title     = {On Event Individuation for Document-Level Information Extraction},
  abbr      = {EMNLP Findings},
  author    = {Gantt, William  and
               Kriz, Reno  and
               Chen, Yunmo  and
               Vashishtha, Siddharth  and
               White, Aaron},
  editor    = {Bouamor, Houda  and
               Pino, Juan  and
               Bali, Kalika},
  booktitle = {Findings of the Association for Computational Linguistics: EMNLP 2023},
  month     = dec,
  year      = {2023},
  address   = {Singapore},
  publisher = {Association for Computational Linguistics},
  url       = {https://aclanthology.org/2023.findings-emnlp.862},
  doi       = {10.18653/v1/2023.findings-emnlp.862},
  pages     = {12938--12958},
  abstract  = {As information extraction (IE) systems have grown more adept at processing whole documents, the classic task of *template filling* has seen renewed interest as a benchmark for document-level IE. In this position paper, we call into question the suitability of template filling for this purpose. We argue that the task demands definitive answers to thorny questions of *event individuation* {---} the problem of distinguishing distinct events {---} about which even human experts disagree. Through an annotation study and error analysis, we show that this raises concerns about the usefulness of template filling metrics, the quality of datasets for the task, and the ability of models to learn it. Finally, we consider possible solutions.}
}

@inproceedings{vashishtha-etal-2019-fine,
  title     = {Fine-Grained Temporal Relation Extraction},
  abbr      = {ACL},
  author    = {Vashishtha, Siddharth  and
               Van Durme, Benjamin  and
               White, Aaron Steven},
  booktitle = {Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics},
  month     = jul,
  year      = {2019},
  address   = {Florence, Italy},
  publisher = {Association for Computational Linguistics},
  pdf       = {https://aclanthology.org/P19-1280},
  doi       = {10.18653/v1/P19-1280},
  pages     = {2906--2919},
  abstract  = {We present a novel semantic framework for modeling temporal relations and event durations that maps pairs of events to real-valued scales. We use this framework to construct the largest temporal relations dataset to date, covering the entirety of the Universal Dependencies English Web Treebank. We use this dataset to train models for jointly predicting fine-grained temporal relations and event durations. We report strong results on our data and show the efficacy of a transfer-learning approach for predicting categorical relations.},
  selected  = {true},
  code      = {https://hub.docker.com/r/sidvash/temporal},
  website   = {http://decomp.io/projects/time/}
}

@inproceedings{xia-etal-2021-lome,
  title     = {{LOME}: Large Ontology Multilingual Extraction},
  abbr      = {EACL},
  author    = {Xia, Patrick  and
               Qin, Guanghui  and
               Vashishtha, Siddharth  and
               Chen, Yunmo  and
               Chen, Tongfei  and
               May, Chandler  and
               Harman, Craig  and
               Rawlins, Kyle  and
               White, Aaron Steven  and
               Van Durme, Benjamin},
  booktitle = {Proceedings of the 16th Conference of the European Chapter of the Association for Computational Linguistics: System Demonstrations},
  month     = apr,
  year      = {2021},
  address   = {Online},
  publisher = {Association for Computational Linguistics},
  pdf       = {https://aclanthology.org/2021.eacl-demos.19},
  pages     = {149--159},
  website   = {https://nlp.jhu.edu/demos/},
  abstract  = {We present LOME, a system for performing multilingual information extraction. Given a text document as input, our core system identifies spans of textual entity and event mentions with a FrameNet (Baker et al., 1998) parser. It subsequently performs coreference resolution, fine-grained entity typing, and temporal relation prediction between events. By doing so, the system constructs an event and entity focused knowledge graph. We can further apply third-party modules for other types of annotation, like relation extraction. Our (multilingual) first-party modules either outperform or are competitive with the (monolingual) state-of-the-art. We achieve this through the use of multilingual encoders like XLM-R (Conneau et al., 2020) and leveraging multilingual training data. LOME is available as a Docker container on Docker Hub. In addition, a lightweight version of the system is accessible as a web demo.}
}

@inproceedings{vashishtha-etal-2020-temporal,
  title     = {Temporal Reasoning in Natural Language Inference},
  abbr      = {EMNLP Findings},
  author    = {Vashishtha, Siddharth  and
               Poliak, Adam  and
               Lal, Yash Kumar  and
               Van Durme, Benjamin  and
               White, Aaron Steven},
  booktitle = {Findings of the Association for Computational Linguistics: EMNLP},
  month     = nov,
  year      = {2020},
  address   = {Online},
  publisher = {Association for Computational Linguistics},
  pdf       = {https://aclanthology.org/2020.findings-emnlp.363},
  doi       = {10.18653/v1/2020.findings-emnlp.363},
  pages     = {4070--4078},
  selected  = {true},
  code      = {https://github.com/sidsvash26/temporal_nli},
  abstract  = {We introduce five new natural language inference (NLI) datasets focused on temporal reasoning. We recast four existing datasets annotated for event duration{---}how long an event lasts{---}and event ordering{---}how events are temporally arranged{---}into more than one million NLI examples. We use these datasets to investigate how well neural models trained on a popular NLI corpus capture these forms of temporal reasoning.}
}

@inproceedings{white-etal-2020-universal,
  title     = {The Universal Decompositional Semantics Dataset and Decomp Toolkit},
  abbr      = {LREC},
  author    = {White, Aaron Steven  and
               Stengel-Eskin, Elias  and
               Vashishtha, Siddharth  and
               Govindarajan, Venkata Subrahmanyan  and
               Reisinger, Dee Ann  and
               Vieira, Tim  and
               Sakaguchi, Keisuke  and
               Zhang, Sheng  and
               Ferraro, Francis  and
               Rudinger, Rachel  and
               Rawlins, Kyle  and
               Van Durme, Benjamin},
  booktitle = {Proceedings of the 12th Language Resources and Evaluation Conference},
  month     = may,
  year      = {2020},
  address   = {Marseille, France},
  publisher = {European Language Resources Association},
  pdf       = {https://aclanthology.org/2020.lrec-1.699},
  pages     = {5698--5707},
  abstract  = {We present the Universal Decompositional Semantics (UDS) dataset (v1.0), which is bundled with the Decomp toolkit (v0.1). UDS1.0 unifies five high-quality, decompositional semantics-aligned annotation sets within a single semantic graph specification{---}with graph structures defined by the predicative patterns produced by the PredPatt tool and real-valued node and edge attributes constructed using sophisticated normalization procedures. The Decomp toolkit provides a suite of Python 3 tools for querying UDS graphs using SPARQL. Both UDS1.0 and Decomp0.1 are publicly available at http://decomp.io.},
  language  = {English},
  code      = {https://github.com/decompositional-semantics-initiative/decomp},
  isbn      = {979-10-95546-34-4}
}

@inproceedings{bose2020improving,
  abbr      = {AAAI},
  title     = {Improving Semantic Parsing Using Statistical Word Sense Disambiguation (Student Abstract)},
  author    = {Bose, Ritwik and Vashishtha, Siddharth and Allen, James},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  volume    = {34},
  number    = {10},
  pages     = {13757--13758},
  year      = {2020},
  pdf       = {publications/aaai20_wsd_student_abstract.pdf},
  poster    = {posters/aaai20_wsd_poster.pdf}
}